{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## training에 사용할 image size\n",
    "img_width = 128\n",
    "img_height = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tfrecord file 이름과 디렉토리 설정\n",
    "tfrecord_train = 'train.tfrecord'\n",
    "tfrecord_test = 'test.tfrecord'\n",
    "tfrecord_dir = 'tfrecords'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tfrecord file 경로 설정\n",
    "cur_dir = os.getcwd()\n",
    "train_tfr_path = os.path.join(cur_dir, tfrecord_dir, tfrecord_train)\n",
    "test_tfr_path = os.path.join(cur_dir, tfrecord_dir, tfrecord_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 16\n",
    "\n",
    "## class 갯수\n",
    "n_class = 101\n",
    "## training data 수\n",
    "n_train = 6941\n",
    "## test data 수\n",
    "n_test = 1736\n",
    "## learning rate decay ratio\n",
    "lr_decay_ratio = 0.1\n",
    "## 몇 epoch 마다 learning rate을 decay할 것인지\n",
    "lr_decay_epoch_num = 5\n",
    "## image file 위치\n",
    "image_dir = 'caltech101'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(tfrecord_serialized):\n",
    "    features={'image': tf.FixedLenFeature([], tf.string),\n",
    "             'label': tf.FixedLenFeature([], tf.int64)}\n",
    "    parsed_features = tf.parse_single_example(tfrecord_serialized, features)\n",
    "    \n",
    "    image = tf.decode_raw(parsed_features['image'], tf.uint8)\n",
    "    label = tf.cast(parsed_features['label'], tf.int32)\n",
    "    #label_onehot = tf.one_hot(label, depth=n_class)\n",
    "        \n",
    "    #image = tf.reshape(image, [-1, img_height, img_width, 3])\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(train_tfr_path)\n",
    "train_dataset = train_dataset.map(_parse_function, num_parallel_calls=8)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=n_train*2).prefetch(buffer_size=batch_size).batch(batch_size).repeat()\n",
    "#print(train_dataset.output_types, train_dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = tf.data.TFRecordDataset(test_tfr_path)\n",
    "test_dataset = test_dataset.map(_parse_function, num_parallel_calls=8)\n",
    "test_dataset = test_dataset.shuffle(buffer_size=n_train*2).prefetch(buffer_size=batch_size).batch(batch_size).repeat()\n",
    "#print(test_dataset.output_types, test_dataset.output_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types, train_dataset.output_shapes)\n",
    "image, label = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_init = iterator.make_initializer(train_dataset)\n",
    "test_init = iterator.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_post = tf.reshape(image, [-1, img_height, img_width, 3])\n",
    "image_post = tf.cast(image_post, tf.float32) / 255.\n",
    "label_onehot = tf.one_hot(label, depth=n_class)\n",
    "is_train = tf.placeholder(tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = tf.layers.conv2d(inputs=image_post, filters=32, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "bn1 = tf.layers.batch_normalization(pool1, training=is_train)\n",
    "#bn1 = tf.contrib.layers.batch_norm(pool1, decay=0.9, is_training=is_train)\n",
    "#drop1 = tf.layers.dropout(inputs=pool1, rate=0.3, training=is_train)\n",
    "\n",
    "conv2 = tf.layers.conv2d(inputs=bn1, filters=64, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "bn2 = tf.layers.batch_normalization(pool2, training=is_train)\n",
    "#bn2 = tf.contrib.layers.batch_norm(pool2, decay=0.9, is_training=is_train)\n",
    "#drop2 = tf.layers.dropout(inputs=pool2, rate=0.3, training=is_train)\n",
    "\n",
    "conv3 = tf.layers.conv2d(inputs=bn2, filters=128, kernel_size=[3, 3],\n",
    "                        padding=\"SAME\", activation=tf.nn.relu)\n",
    "pool3 = tf.layers.max_pooling2d(inputs=conv3, pool_size=[2, 2],\n",
    "                        padding=\"SAME\", strides=2)\n",
    "bn3 = tf.layers.batch_normalization(pool3, training=is_train)\n",
    "#bn3 = tf.contrib.layers.batch_norm(pool3, decay=0.9, is_training=is_train)\n",
    "#drop3 = tf.layers.dropout(inputs=pool3, rate=0.3, training=is_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat3 = tf.contrib.layers.flatten(bn3)\n",
    "dense4 = tf.layers.dense(inputs=flat3, units=625, activation=tf.nn.relu)\n",
    "bn4 = tf.layers.batch_normalization(dense4, training=is_train)\n",
    "#bn4 = tf.contrib.layers.batch_norm(dense4, decay=0.9, is_training=is_train)\n",
    "#drop4 = tf.layers.dropout(inputs=dense4, rate=0.5, training=is_train)\n",
    "\n",
    "logits = tf.layers.dense(inputs=bn4, units=n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    logits=logits, labels=label_onehot))\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "lr_decay = tf.train.exponential_decay(learning_rate=learning_rate,\n",
    "                                          global_step= global_step,\n",
    "                                          decay_steps=int(n_train/batch_size*lr_decay_epoch_num),\n",
    "                                          decay_rate= lr_decay_ratio,\n",
    "                                          staircase=True)\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(\n",
    "        cost)\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(label_onehot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth =True)))\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "max_test_acc = 0.\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    avg_train_acc = 0.\n",
    "    avg_test_acc = 0.\n",
    "    \n",
    "    total_batch = int(n_train / batch_size)\n",
    "    total_batch_test = int(n_test / batch_size)\n",
    "    \n",
    "    sess.run(train_init)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        #batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        #batch_xs = batch_xs.reshape(-1, time_steps, element_size)\n",
    "        #sess.run([image, label])        \n",
    "        feed_dict = {is_train:True}\n",
    "        acc, c, _ = sess.run([accuracy, cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "        avg_train_acc += acc / total_batch\n",
    "        \n",
    "    sess.run(test_init)\n",
    "        \n",
    "    for i in range(total_batch_test):\n",
    "        #batch_xs, batch_ys = mnist.test.next_batch(batch_size)        \n",
    "        #batch_xs = batch_xs.reshape(-1, time_steps, element_size)\n",
    "        #sess.run([image, label])\n",
    "        feed_dict = {is_train:False}\n",
    "        acc = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        avg_test_acc += acc / total_batch_test\n",
    "\n",
    "    print('Epoch:', '{}'.format(epoch + 1), 'cost =', '{:.8f}'.format(avg_cost), \n",
    "          'train accuracy = ', '{:.4f}'.format(avg_train_acc), \n",
    "          'test accuracy = ', '{:.4f}'.format(avg_test_acc))\n",
    "\n",
    "print('Learning Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()\n",
    "image_path = os.path.join(cur_dir, image_dir)\n",
    "\n",
    "class_names = sorted(os.listdir(image_path))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    if predicted_label == true_label:\n",
    "        color = 'blue'\n",
    "    else:\n",
    "        color = 'red'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    #plt.xticks([])\n",
    "    plt.xticks(range(n_class), class_names, rotation=90)\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(n_class), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1]) \n",
    "    predicted_label = np.argmax(predictions_array)\n",
    " \n",
    "    thisplot[predicted_label].set_color('red')\n",
    "    thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(test_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = tf.nn.softmax(logits)\n",
    "imgs, lbs, x, y = sess.run([image, label, image_post, label_onehot])\n",
    "imgs = np.reshape(imgs, [-1, img_height, img_width, 3])\n",
    "predictions = sess.run(prob, feed_dict={image_post:x, label_onehot:y, is_train:False})\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(3*2*num_cols, 3*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, predictions, lbs, imgs)\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, predictions, lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
